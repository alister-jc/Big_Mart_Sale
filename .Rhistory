ifelse(Item_MRP >= 136 & Item_MRP < 203, "3rd", "4th")))]
str(combi)
combi[, Outlet_Size_num := ifelse(Outlet_Size == "Small", 0,
ifelse(Outlet_Size == "Medium", 1,2))]
combi[, Outlet_Location_Type_num := ifelse(Outlet_Location_Type == "Tier 3", 0,
ifelse(Outlet_Location_Type == "Tier 2", 1, 2))]
combi[, c("Outlet_Size", "Outlet_Location_Type") := NULL]
ohe = dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
combi[, Item_Visibility := log(Item_Visibility + 1)] #log +1 to avoid division by zero
combi[, price_per_unit_wt := log(price_per_unit_wt +1)]
num_vars = which(sapply(combi, is.numeric)) #index of numeric features
num_vars_name = names(num_vars)
combi_numeric = combi[, setdiff(num_vars_name, "Item_Outlet_Sales"), with = F]
prep_num = preProcess(combi_numeric, method = c("center", "scale"))
combi_numeric_norm = predict(prep_num, combi_numeric)
combi[, setdiff(num_vars_name, "Item_Outlet_Sales") := NULL] #removing numeric independent variable
combi = cbind(combi, combi_numeric_norm)
train = combi[1:nrow(train)]
test = combi[(nrow(train) + 1):nrow(combi)]
test[, Item_Outlet_Sales := NULL]#Removing item_outlet_sales as it contains
cor_train = cor(train[,-c("Item_Identifier")])
corrplot(cor_train, method = "pie", type = "lower", tl.cex = 0.9)
str(combi)
str(train)
linear_reg_mod = lm(Item_Outlet_Sales ~ ., data = train[, -c("Item_Identifier","Item_Weight","Item_Fat_ContentNon-Edible", "Item_Fat_ContentRegular", "Item_Visibility")])
submission$Item_Outlet_Sales = predict(linear_reg_mod, test[,-c("Item_Identifier")])
write.csv(submission, "Linear_Reg_submit.csv", row.names = F)
set.seed(1237)
my_control = trainControl(method="cv", number=5) # 5-fold CV
tgrid = expand.grid(
.mtry = c(3:10),
.splitrule = "variance",
.min.node.size = c(10,15,20)
)
rf_mod = train(x = train[, -c("Item_Identifier", "Item_Outlet_Sales")],
y = train$Item_Outlet_Sales,
method='ranger',
trControl= my_control,
tuneGrid = tgrid,
num.trees = 400,
importance = "permutation")
setwd("C:/Users/Neebal/Desktop/Projects in R/Big mart")
library(data.table) # used for reading and manipulation of data
library(dplyr)      # used for data manipulation and joining
library(ggplot2)    # used for ploting
library(caret)      # used for modeling
library(corrplot)   # used for making correlation plot
library(xgboost)    # used for building XGBoost model
library(cowplot)    # used for combining multiple plots
library(magrittr)
train = fread("Train_UWu5bXk.csv")
test = fread("Test_u94Q5KV.csv")
submission = fread("SampleSubmission_TmnO39y.csv")
dim(train)
dim(test)
names(train)
names(test)
str(train)
str(test)
test[, Item_Outlet_Sales := NA]
combi = rbind(train, test)
dim(combi)
str(combi)
combi$Item_Fat_Content[combi$Item_Fat_Content == "LF"] = "Low Fat"
combi$Item_Fat_Content[combi$Item_Fat_Content == "low fat"] = "Low Fat"
combi$Item_Fat_Content[combi$Item_Fat_Content == "reg"] = "Regular"
train = combi[1:nrow(train)] # extracting train data from the combined data
sum(is.na(combi$Item_Weight))
missing_index = which(is.na(combi$Item_Weight))
for(i in missing_index){
item = combi$Item_Identifier[i]
combi$Item_Weight[i]= mean(combi$Item_Weight[combi$Item_Identifier == item], na.rm = T)
}
sum(is.na(combi$Item_Weight))
zero_index = which(combi$Item_Visibility == 0)
for(i in zero_index){
item = combi$Item_Identifier[i]
combi$Item_Visibility[i] = mean(combi$Item_Visibility[combi$Item_Identifier ==item], na.rm = T)
}
perishable = c("Breads", "Breakfast", "Dairy", "Fruits and Vegetables", "Meat", "Seafood")
non_perishable = c("Baking Goods", "Canned", "Frozen Foods", "Hard Drinks", "Health and Hygiene", "Household", "Soft Drinks")
combi[, Item_Type_new := ifelse(Item_Type %in% perishable, "perishable", ifelse(Item_Type %in% non_perishable, "non_perishable", "not_sure"))]
table(combi$Item_Type, substr(combi$Item_Identifier, 1, 2))
combi[, Item_category := substr(combi$Item_Identifier, 1, 2)]
combi$Item_Fat_Content[combi$Item_category == "NC"] = "Non-Edible"
combi[, Outlet_Years := 2018 - combi$Outlet_Establishment_Year]
combi$Outlet_Establishment_Year = as.factor(combi$Outlet_Establishment_Year)
combi[,item_MRP_clusters := ifelse(Item_MRP < 69, "1st",
ifelse(Item_MRP >= 69 & Item_MRP < 136, "2nd",
ifelse(Item_MRP >= 136 & Item_MRP < 203, "3rd", "4th")))]
str(combi)
combi[, Outlet_Size_num := ifelse(Outlet_Size == "Small", 0,
ifelse(Outlet_Size == "Medium", 1,2))]
combi[, Outlet_Location_Type_num := ifelse(Outlet_Location_Type == "Tier 3", 0,
ifelse(Outlet_Location_Type == "Tier 2", 1, 2))]
combi[, c("Outlet_Size", "Outlet_Location_Type") := NULL]
ohe = dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
combi[, Item_Visibility := log(Item_Visibility + 1)] #log +1 to avoid division by zero
combi[, price_per_unit_wt := log(price_per_unit_wt +1)]
combi[, Item_Visibility := log(Item_Visibility + 1)] #log +1 to avoid division by zero
combi[, price_per_unit_wt := log(price_per_unit_wt +1)]
num_vars = which(sapply(combi, is.numeric)) #index of numeric features
num_vars_name = names(num_vars)
combi_numeric = combi[, setdiff(num_vars_name, "Item_Outlet_Sales"), with = F]
prep_num = preProcess(combi_numeric, method = c("center", "scale"))
combi_numeric_norm = predict(prep_num, combi_numeric)
combi[, setdiff(num_vars_name, "Item_Outlet_Sales") := NULL] #removing numeric independent variable
combi = cbind(combi, combi_numeric_norm)
train = combi[1:nrow(train)]
test = combi[(nrow(train) + 1):nrow(combi)]
test[, Item_Outlet_Sales := NULL]#Removing item_outlet_sales as it contains
cor_train = cor(train[,-c("Item_Identifier")])
corrplot(cor_train, method = "pie", type = "lower", tl.cex = 0.9)
str(combi)
str(train)
set.seed(1237)
my_control = trainControl(method="cv", number=5) # 5-fold CV
tgrid = expand.grid(
.mtry = c(3:10),
.splitrule = "variance",
.min.node.size = c(10,15,20)
)
rf_mod = train(x = train[, -c("Item_Identifier", "Item_Outlet_Sales")],
y = train$Item_Outlet_Sales,
method='ranger',
trControl= my_control,
tuneGrid = tgrid,
num.trees = 400,
importance = "permutation")
submission$Item_Outlet_Sales = predict(rf_mod, test[,-c("Item_Identifier")])
write.csv(submission, "Random_Forest_submit.csv", row.names = F)
plot(rf_mod)
plot(varImp(rf_mod))
library("xgboost", lib.loc="~/R/R-3.4.1/library")
install.packages(c("broom", "callr", "caTools", "cowplot", "digest", "e1071", "foreign", "glue", "ipred", "iterators", "kernlab", "lava", "ModelMetrics", "modeltools", "party", "pillar", "pkgconfig", "pls", "processx", "rattle", "Rcpp", "RcppArmadillo", "rlang", "robustbase", "rpart.plot", "sandwich", "scales", "stringi", "survival", "tinytex", "XML", "xts", "yaml", "zoo"))
install.packages(c("broom", "callr", "caTools", "cowplot", "digest", "e1071", "foreign", "glue", "ipred", "iterators", "kernlab", "lava", "ModelMetrics", "modeltools", "party", "pillar", "pkgconfig", "pls", "processx", "rattle", "Rcpp", "RcppArmadillo", "rlang", "robustbase", "rpart.plot", "sandwich", "scales", "stringi", "survival", "tinytex", "XML", "xts", "yaml", "zoo"))
install.packages(c("broom", "callr", "caTools", "cowplot", "digest", "e1071", "foreign", "glue", "ipred", "iterators", "kernlab", "lava", "ModelMetrics", "modeltools", "party", "pillar", "pkgconfig", "pls", "processx", "rattle", "Rcpp", "RcppArmadillo", "rlang", "robustbase", "rpart.plot", "sandwich", "scales", "stringi", "survival", "tinytex", "XML", "xts", "yaml", "zoo"))
library("xgboost", lib.loc="~/R/R-3.4.1/library")
param_list = list(
objective = "reg:linear",
eta=0.01,
gamma = 1,
max_depth=6,
subsample=0.8,
colsample_bytree=0.5
)
dtrain = xgb.DMatrix(data = as.matrix(train[,-c("Item_Identifier", "Item_Outlet_Sales")]),
label= train$Item_Outlet_Sales)
dtest = xgb.DMatrix(data = as.matrix(test[,-c("Item_Identifier")]))
set.seed(112)
xgbcv = xgb.cv(params = param_list,
data = dtrain,
nrounds = 1000,
nfold = 5,
print_every_n = 10,
early_stopping_rounds = 30,
maximize = F)
setwd("C:/Users/Neebal/Desktop/Projects in R/Big mart")
set.seed(112)
xgbcv = xgb.cv(params = param_list,
data = dtrain,
nrounds = 1000,
nfold = 5,
print_every_n = 10,
early_stopping_rounds = 30,
maximize = F)
library(data.table) # used for reading and manipulation of data
library(dplyr)      # used for data manipulation and joining
library(ggplot2)    # used for ploting
library(caret)      # used for modeling
library(corrplot)   # used for making correlation plot
library(xgboost)    # used for building XGBoost model
library(cowplot)    # used for combining multiple plots
library(magrittr)
train = fread("Train_UWu5bXk.csv")
test = fread("Test_u94Q5KV.csv")
submission = fread("SampleSubmission_TmnO39y.csv")
test[, Item_Outlet_Sales := NA]
combi = rbind(train, test)
dim(combi)
str(combi)
train = combi[1:nrow(train)] # extracting train data from the combined data
sum(is.na(combi$Item_Weight))
missing_index = which(is.na(combi$Item_Weight))
for(i in missing_index){
item = combi$Item_Identifier[i]
combi$Item_Weight[i]= mean(combi$Item_Weight[combi$Item_Identifier == item], na.rm = T)
}
sum(is.na(combi$Item_Weight))
zero_index = which(combi$Item_Visibility == 0)
for(i in zero_index){
item = combi$Item_Identifier[i]
combi$Item_Visibility[i] = mean(combi$Item_Visibility[combi$Item_Identifier ==item], na.rm = T)
perishable = c("Breads", "Breakfast", "Dairy", "Fruits and Vegetables", "Meat", "Seafood")
non_perishable = c("Baking Goods", "Canned", "Frozen Foods", "Hard Drinks", "Health and Hygiene", "Household", "Soft Drinks")
combi[, Item_Type_new := ifelse(Item_Type %in% perishable, "perishable", ifelse(Item_Type %in% non_perishable, "non_perishable", "not_sure"))]
combi[, Item_Type_new := ifelse(Item_Type %in% perishable, "perishable", ifelse(Item_Type %in% non_perishable, "non_perishable", "not_sure"))]
table(combi$Item_Type, substr(combi$Item_Identifier, 1, 2))
combi[, Item_category := substr(combi$Item_Identifier, 1, 2)]
combi$Item_Fat_Content[combi$Item_category == "NC"] = "Non-Edible"
combi[, Outlet_Years := 2018 - combi$Outlet_Establishment_Year]
combi$Outlet_Establishment_Year = as.factor(combi$Outlet_Establishment_Year)
combi[, price_per_unit_wt := Item_MRP/Item_Weight]
combi[,item_MRP_clusters := ifelse(Item_MRP < 69, "1st",
ifelse(Item_MRP >= 69 & Item_MRP < 136, "2nd",
ifelse(Item_MRP >= 136 & Item_MRP < 203, "3rd", "4th")))]
str(combi)
str(combi)
setwd("C:/Users/Neebal/Desktop/Projects in R/Big mart")
library(data.table) # used for reading and manipulation of data
library(dplyr)      # used for data manipulation and joining
library(ggplot2)    # used for ploting
library(caret)      # used for modeling
library(corrplot)   # used for making correlation plot
library(xgboost)    # used for building XGBoost model
library(cowplot)    # used for combining multiple plots
library(magrittr)
library("ggplot2", lib.loc="~/R/R-3.4.1/library")
library("xgboost", lib.loc="~/R/R-3.4.1/library")
library("data.table", lib.loc="~/R/R-3.4.1/library")
library("caret", lib.loc="~/R/R-3.4.1/library")
library("magrittr", lib.loc="~/R/R-3.4.1/library")
library("corrplot", lib.loc="~/R/R-3.4.1/library")
train = fread("Train_UWu5bXk.csv")
test = fread("Test_u94Q5KV.csv")
submission = fread("SampleSubmission_TmnO39y.csv")
dim(train)
dim(test)
names(train)
names(test)
str(train)
str(test)
test[, Item_Outlet_Sales := NA]
combi = rbind(train, test)
dim(combi)
str(combi)
combi$Item_Fat_Content[combi$Item_Fat_Content == "LF"] = "Low Fat"
combi$Item_Fat_Content[combi$Item_Fat_Content == "low fat"] = "Low Fat"
combi$Item_Fat_Content[combi$Item_Fat_Content == "reg"] = "Regular"
train = combi[1:nrow(train)] # extracting train data from the combined data
sum(is.na(combi$Item_Weight))
missing_index = which(is.na(combi$Item_Weight))
for(i in missing_index){
item = combi$Item_Identifier[i]
combi$Item_Weight[i]= mean(combi$Item_Weight[combi$Item_Identifier == item], na.rm = T)
}
sum(is.na(combi$Item_Weight))
zero_index = which(combi$Item_Visibility == 0)
for(i in zero_index){
item = combi$Item_Identifier[i]
combi$Item_Visibility[i] = mean(combi$Item_Visibility[combi$Item_Identifier ==item], na.rm = T)
}
perishable = c("Breads", "Breakfast", "Dairy", "Fruits and Vegetables", "Meat", "Seafood")
non_perishable = c("Baking Goods", "Canned", "Frozen Foods", "Hard Drinks", "Health and Hygiene", "Household", "Soft Drinks")
combi[, Item_Type_new := ifelse(Item_Type %in% perishable, "perishable", ifelse(Item_Type %in% non_perishable, "non_perishable", "not_sure"))]
table(combi$Item_Type, substr(combi$Item_Identifier, 1, 2))
combi[, Item_category := substr(combi$Item_Identifier, 1, 2)]
combi$Item_Fat_Content[combi$Item_category == "NC"] = "Non-Edible"
combi[, Outlet_Years := 2018 - combi$Outlet_Establishment_Year]
combi$Outlet_Establishment_Year = as.factor(combi$Outlet_Establishment_Year)
combi[, price_per_unit_wt := Item_MRP/Item_Weight]
combi[,item_MRP_clusters := ifelse(Item_MRP < 69, "1st",
ifelse(Item_MRP >= 69 & Item_MRP < 136, "2nd",
ifelse(Item_MRP >= 136 & Item_MRP < 203, "3rd", "4th")))]
str(combi)
combi[, Outlet_Size_num := ifelse(Outlet_Size == "Small", 0,
ifelse(Outlet_Size == "Medium", 1,2))]
combi[, Outlet_Location_Type_num := ifelse(Outlet_Location_Type == "Tier 3", 0,
ifelse(Outlet_Location_Type == "Tier 2", 1, 2))]
combi[, c("Outlet_Size", "Outlet_Location_Type") := NULL]
ohe = dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
library("caret", lib.loc="~/R/R-3.4.1/library")
ohe = dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
#One Hot encoding for categorical variables
ohe <- dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df <- data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
#Using log transformation
combi[, Item_Visibility := log(Item_Visibility + 1)] #log +1 to avoid division by zero
combi[, price_per_unit_wt := log(price_per_unit_wt +1)]
num_vars = which(sapply(combi, is.numeric)) #index of numeric features
num_vars_name = names(num_vars)
combi_numeric = combi[, setdiff(num_vars_name, "Item_Outlet_Sales"), with = F]
prep_num = preProcess(combi_numeric, method = c("center", "scale"))
combi_numeric_norm = predict(prep_num, combi_numeric)
combi[, setdiff(num_vars_name, "Item_Outlet_Sales") := NULL] #removing numeric independent variable
combi = cbind(combi, combi_numeric_norm)
train = combi[1:nrow(train)]
test = combi[(nrow(train) + 1):nrow(combi)]
test[, Item_Outlet_Sales := NULL]#Removing item_outlet_sales as it contains
cor_train = cor(train[,-c("Item_Identifier")])
corrplot(cor_train, method = "pie", type = "lower", tl.cex = 0.9)
str(combi)
str(train)
source('C:/Users/Neebal/Desktop/Projects in R/Big mart/Big_mart_R.R', echo=TRUE)
library("dplyr", lib.loc="~/R/R-3.4.1/library")
param_list = list(
objective = "reg:linear",
eta=0.01,
gamma = 1,
max_depth=6,
subsample=0.8,
colsample_bytree=0.5
)
dtrain = xgb.DMatrix(data = as.matrix(train[,-c("Item_Identifier", "Item_Outlet_Sales")]),
label= train$Item_Outlet_Sales)
dtest = xgb.DMatrix(data = as.matrix(test[,-c("Item_Identifier")]))
library("xgboost", lib.loc="~/R/R-3.4.1/library")
dtrain = xgb.DMatrix(data = as.matrix(train[,-c("Item_Identifier", "Item_Outlet_Sales")]),
label= train$Item_Outlet_Sales)
dtest = xgb.DMatrix(data = as.matrix(test[,-c("Item_Identifier")]))
install.packages("xgboost")
library(xgboost)
install.packages("dplyr")
library(dplyr)
param_list = list(
objective = "reg:linear",
eta=0.01,
gamma = 1,
max_depth=6,
subsample=0.8,
colsample_bytree=0.5
)
dtrain = xgb.DMatrix(data = as.matrix(train[,-c("Item_Identifier", "Item_Outlet_Sales")]),
label= train$Item_Outlet_Sales)
dtest = xgb.DMatrix(data = as.matrix(test[,-c("Item_Identifier")]))
set.seed(112)
xgbcv = xgb.cv(params = param_list,
data = dtrain,
nrounds = 1000,
nfold = 5,
print_every_n = 10,
early_stopping_rounds = 30,
maximize = F)
xgb_model = xgb.train(data = dtrain, params = param_list, nrounds = 430)
#Writing on the submission file
submission$Item_Outlet_Sales = predict(xgbcv, test[,-c("Item_Identifier")])
write.csv(submission, "XGBoost_submit.csv", row.names = F)
#Writing on the submission file
submission$Item_Outlet_Sales = predict(xgb_model, test[,-c("Item_Identifier")])
write.csv(submission, "XGBoost_submit.csv", row.names = F)
submission$Item_Outlet_Sales = predict(xgb_model, test[,-c("Item_Identifier")])
ohe <- dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df <- data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
ohe = dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
install.packages(caret)
install.packages("caret")
library(caret)
ohe = dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
ohe = caret::dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
library(caret)
install.packages("scales")
library(caret)
install.packages("robustbase")
library(robustbase)
library(scales)
library(caret)
install.packages("kernlab")
library(kernlab)
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
library(caret)
library("caret", lib.loc="~/R/R-3.4.1/library")
install.packages("stringi")
library(caret)
install.packages("ipred")
library(ipred)
library(survival)
library(caret)
ohe = dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
submission$Item_Outlet_Sales = predict(xgb_model, test[,-c("Item_Identifier")])
setwd("C:/Users/Neebal/Desktop/Projects in R/Big mart")
library(data.table) # used for reading and manipulation of data
library(dplyr)      # used for data manipulation and joining
library(ggplot2)    # used for ploting
library(caret)      # used for modeling
library(corrplot)   # used for making correlation plot
library(xgboost)    # used for building XGBoost model
library(cowplot)    # used for combining multiple plots
library(magrittr)
install.packages(xgboost)
install.packages
install.packages("xgboost")
install.packages("data.table")
install.packages("data.table")
install.packages("caret")
library(caret)
library(xgboost)
library(dplyr)
train = fread("Train_UWu5bXk.csv")
test = fread("Test_u94Q5KV.csv")
submission = fread("SampleSubmission_TmnO39y.csv")
test[, Item_Outlet_Sales := NA]
combi = rbind(train, test)
combi$Item_Fat_Content[combi$Item_Fat_Content == "LF"] = "Low Fat"
combi$Item_Fat_Content[combi$Item_Fat_Content == "low fat"] = "Low Fat"
combi$Item_Fat_Content[combi$Item_Fat_Content == "reg"] = "Regular"
ggplot(combi %>% group_by(Item_Fat_Content) %>% summarise(Count = n())) +
geom_bar(aes(Item_Fat_Content, Count), stat = "identity", fill = "coral1")
train = combi[1:nrow(train)] # extracting train data from the combined data
sum(is.na(combi$Item_Weight))
missing_index = which(is.na(combi$Item_Weight))
for(i in missing_index){
item = combi$Item_Identifier[i]
combi$Item_Weight[i]= mean(combi$Item_Weight[combi$Item_Identifier == item], na.rm = T)
}
sum(is.na(combi$Item_Weight))
zero_index = which(combi$Item_Visibility == 0)
for(i in zero_index){
item = combi$Item_Identifier[i]
combi$Item_Visibility[i] = mean(combi$Item_Visibility[combi$Item_Identifier ==item], na.rm = T)
}
perishable = c("Breads", "Breakfast", "Dairy", "Fruits and Vegetables", "Meat", "Seafood")
non_perishable = c("Baking Goods", "Canned", "Frozen Foods", "Hard Drinks", "Health and Hygiene", "Household", "Soft Drinks")
combi[, Item_Type_new := ifelse(Item_Type %in% perishable, "perishable", ifelse(Item_Type %in% non_perishable, "non_perishable", "not_sure"))]
table(combi$Item_Type, substr(combi$Item_Identifier, 1, 2))
combi[, Item_category := substr(combi$Item_Identifier, 1, 2)]
combi$Item_Fat_Content[combi$Item_category == "NC"] = "Non-Edible"
combi[, Outlet_Years := 2018 - combi$Outlet_Establishment_Year]
combi$Outlet_Establishment_Year = as.factor(combi$Outlet_Establishment_Year)
combi[, price_per_unit_wt := Item_MRP/Item_Weight]
# creating new independent variable - Item_MRP_clusters
combi[,item_MRP_clusters := ifelse(Item_MRP < 69, "1st",
ifelse(Item_MRP >= 69 & Item_MRP < 136, "2nd",
ifelse(Item_MRP >= 136 & Item_MRP < 203, "3rd", "4th")))]
str(combi)
combi[, Outlet_Size_num := ifelse(Outlet_Size == "Small", 0,
ifelse(Outlet_Size == "Medium", 1,2))]
combi[, Outlet_Location_Type_num := ifelse(Outlet_Location_Type == "Tier 3", 0,
ifelse(Outlet_Location_Type == "Tier 2", 1, 2))]
combi[, c("Outlet_Size", "Outlet_Location_Type") := NULL]
ohe = dummyVars("~.", data = combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")], fullRank = T)
ohe_df = data.table(predict(ohe, combi[, -c("Item_Identifier", "Outlet_Establishment_Year", "Item_Type")]))
combi = cbind(combi[, "Item_Identifier"], ohe_df)
combi[, Item_Visibility := log(Item_Visibility + 1)] #log +1 to avoid division by zero
combi[, price_per_unit_wt := log(price_per_unit_wt +1)]
num_vars = which(sapply(combi, is.numeric)) #index of numeric features
num_vars_name = names(num_vars)
combi_numeric = combi[, setdiff(num_vars_name, "Item_Outlet_Sales"), with = F]
prep_num = preProcess(combi_numeric, method = c("center", "scale"))
combi_numeric_norm = predict(prep_num, combi_numeric)
combi[, setdiff(num_vars_name, "Item_Outlet_Sales") := NULL] #removing numeric independent variable
combi = cbind(combi, combi_numeric_norm)
train = combi[1:nrow(train)]
test = combi[(nrow(train) + 1):nrow(combi)]
test[, Item_Outlet_Sales := NULL]#Removing item_outlet_sales as it contains
cor_train = cor(train[,-c("Item_Identifier")])
corrplot(cor_train, method = "pie", type = "lower", tl.cex = 0.9)
str(combi)
str(train)
param_list = list(
objective = "reg:linear",
eta=0.01,
gamma = 1,
max_depth=6,
subsample=0.8,
colsample_bytree=0.5
)
dtrain = xgb.DMatrix(data = as.matrix(train[,-c("Item_Identifier", "Item_Outlet_Sales")]),
label= train$Item_Outlet_Sales)
dtest = xgb.DMatrix(data = as.matrix(test[,-c("Item_Identifier")]))
set.seed(112)
xgbcv = xgb.cv(params = param_list,
data = dtrain,
nrounds = 1000,
nfold = 5,
print_every_n = 10,
early_stopping_rounds = 30,
maximize = F)
xgb_model = xgb.train(data = dtrain, params = param_list, nrounds = 430)
submission$Item_Outlet_Sales = predict(xgb_model, test[,-c("Item_Identifier")])
View(train)
View(test)
View(submission)
submission$Item_Outlet_Sales = predict(data.matrix(xgb_model), test[,-c("Item_Identifier")])
submission$Item_Outlet_Sales = predict(data.matrix(xgb_model), data.matrix(test[,-c("Item_Identifier"))])
submission$Item_Outlet_Sales = predict(data.matrix(xgb_model), data.matrix(test[,-c("Item_Identifier")]))
write.csv(submission, "XGBoost_submit.csv", row.names = F)
View(submission)
submission$Item_Outlet_Sales = predict(as.matrix(xgb_model), as.matrix(test[,-c("Item_Identifier")]))
write.csv(submission, "XGBoost_submit.csv", row.names = F)
View(submission)
submission$Item_Outlet_Sales = predict(xgb_model, test[,-c("Item_Identifier")])
dtrain = xgb.DMatrix(data = as.matrix(train[,-c("Item_Identifier", "Item_Outlet_Sales")]),
label= train$Item_Outlet_Sales)
dtest = xgb.DMatrix(data = as.matrix(test[,-c("Item_Identifier")]))
xgb_model = xgb.train(data = dtrain, params = param_list, nrounds = 430)
submission$Item_Outlet_Sales = predict(xgb_model, dtest[,-c("Item_Identifier")])
submission$Item_Outlet_Sales = predict(xgb_model, as.matrix(test[,-c("Item_Identifier")]))
write.csv(submission, "XGBoost.csv", row.names = F)
View(submission)
var_imp = xgb.importance(feature_names = setdiff(names(train), c("Item_Identifier", "Item_Outlet_Sales")),
model = xgb_model)
xgb.plot.importance(var_imp)
